# my global config
global:
 scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
 evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
 # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
 - job_name: 'prometheus'
   static_configs:
     - targets: ['192.168.122.5:9090']

 - job_name: 'backend_1'
   metrics_path: '/q/metrics' # путь, по которому генерируются метрики (откуда брать)
   scrape_interval: 3s        # период запроса
   static_configs:
     - targets: ['192.168.122.7:8081'] # адрес, где запущен бэк

 - job_name: 'backend_2'
   metrics_path: '/q/metrics'
   scrape_interval: 3s
   static_configs:
     - targets: ['192.168.122.8:8082']
